{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b4e1d0b-7977-4a92-86ba-66f3416d385b",
   "metadata": {},
   "source": [
    "1. Install chromadb in python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12fb5082-a2eb-4254-b2b3-19768871df74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d340f35c-4fd2-4c19-a5b3-f651ec13b1ec",
   "metadata": {},
   "source": [
    "2. Get the Chroma Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0ffc7db-41f4-4350-a875-e63a0b20ba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c671ace1-6e72-48d9-a5b9-cc92dc0cb97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d19d62-9750-4188-8cf1-c2683d8103ef",
   "metadata": {},
   "source": [
    "3. Create a collection\n",
    "   * Collections are where you'll store your embeddings, documents, and any additional metadata. You can create a collection with a name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4eb65e1-7b49-4c05-8076-5a4b9ba20961",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_collection = chroma_client.create_collection(name=\"resume\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "373adfb6-a90d-4e53-baf3-be9058b1bfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.create_collection(name=\"my_collection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f392b7-2442-46f0-971f-dd59ba5b24e8",
   "metadata": {},
   "source": [
    "4. Add some text documents to the collection\n",
    "   * Chroma will store your text, and handle tokenization, embedding, and indexing automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00aedb79-3ac9-449a-a094-7d0632c0d6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection.add(\n",
    "#     ids: \n",
    "#     embeddings:\n",
    "#     metadatas:\n",
    "#     documents: \n",
    "#     images:\n",
    "#     uris: \n",
    "# ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a13b81e5-2e5e-467f-a0cc-c23f3034acf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aakas\\.cache\\chroma\\onnx_models\\all-MiniLM-L6-v2\\onnx.tar.gz: 100%|█████| 79.3M/79.3M [00:29<00:00, 2.84MiB/s]\n"
     ]
    }
   ],
   "source": [
    "collection.add(\n",
    "    documents=[\"This is a document\",\"This is another\"],\n",
    "    metadatas=[{\"source\":\"my_source\"},{\"source\":\"my_source\"}],\n",
    "    ids=[\"id1\",\"id2\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4d7f07d-48e7-4513-9a36-5488fad0939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_collection.add(\n",
    "    documents=[\"Developed a Flask-based QnA bot, implementing API endpoints for file management and answer generation\",\n",
    "              \"Developed a text summarization project using Facebook’s BART model for efficient content abstraction and information extraction.\",\n",
    "              \"Engineered Flask-based API for report analysis, integrating AWS Textract for PDF data extraction\",\n",
    "              \"Developed a robust document classifier usingDenseNet121, achieving exceptional 99.55% accuracy by fine-tuning and customizing model architecture\"],\n",
    "    metadatas=[{\"source\":\"project1\"},{\"source\":\"project2\"},{\"source\":\"project3\"},{\"source\":\"project4\"}],\n",
    "    ids=[\"id1\",\"id2\", \"id3\",\"id4\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606f3d23-1f48-4db5-b55d-90498b35a69b",
   "metadata": {},
   "source": [
    "* If you have already generated embeddings yourself, you can load them directly in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13fba5da-4306-4be6-9dfa-e7c8f1bd9d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection1 = chroma_client.create_collection(name=\"my_collection1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80f6c42e-57c9-404e-8dd6-5fbd9c1b29e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection1.add(\n",
    "    embeddings=[[1.2,2.3,4.5],[6.7,8.2,9.2]],\n",
    "    documents=[\"This is document\",\"This is another documents=\"],\n",
    "    metadatas=[{\"source\":\"my_source\"},{\"source\":\"my_source\"}],\n",
    "    ids=[\"id1\",\"id2\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a524a5-e00d-4859-a12e-e5294e3a80a1",
   "metadata": {},
   "source": [
    "5. Query the collection\n",
    "   * You can query the collection with a list of query texts, and Chroma will return the n most similar results. It's that easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54e197d9-27fe-4530-bb63-7f53bd8783a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection.query(\n",
    "#     query_embeddings: \n",
    "#     query_texts: \n",
    "#     query_images:\n",
    "#     query_uris: \n",
    "#     n_results:,\n",
    "#     where: Optional\n",
    "#     where_document: \n",
    "#     include: = ['metadatas', 'documents', 'distances'],\n",
    "# ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fee1e4b-6b14-4b1e-9637-a632020cc65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collection.query(\n",
    "    query_texts=[\"This is a query document\"],\n",
    "    n_results=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae0412a9-5bca-4083-a4d2-2e5087ee8016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['id1', 'id2']],\n",
       " 'distances': [[0.7111214399337769, 1.7439494132995605]],\n",
       " 'metadatas': [[{'source': 'my_source'}, {'source': 'my_source'}]],\n",
       " 'embeddings': None,\n",
       " 'documents': [['This is a document', 'This is another']],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90de89f6-4c90-4da5-963f-a783640ba58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['id3', 'id4']],\n",
       " 'distances': [[1.4777964353561401, 1.6031930446624756]],\n",
       " 'metadatas': [[{'source': 'project3'}, {'source': 'project4'}]],\n",
       " 'embeddings': None,\n",
       " 'documents': [['Engineered Flask-based API for report analysis, integrating AWS Textract for PDF data extraction',\n",
       "   'Developed a robust document classifier usingDenseNet121, achieving exceptional 99.55% accuracy by fine-tuning and customizing model architecture']],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_collection.query(\n",
    "    query_texts=\"Document GPT\",\n",
    "    n_results=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "739505ed-1973-4685-8b5a-6713a890db0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['id1', 'id3', 'id2']],\n",
       " 'distances': [[0.44186607003211975, 1.4539411067962646, 1.7471104860305786]],\n",
       " 'metadatas': [[{'source': 'project1'},\n",
       "   {'source': 'project3'},\n",
       "   {'source': 'project2'}]],\n",
       " 'embeddings': None,\n",
       " 'documents': [['Developed a Flask-based QnA bot, implementing API endpoints for file management and answer generation',\n",
       "   'Engineered Flask-based API for report analysis, integrating AWS Textract for PDF data extraction',\n",
       "   'Developed a text summarization project using Facebook’s BART model for efficient content abstraction and information extraction.']],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_collection.query(\n",
    "    query_texts=\"Flask-based QnA bot\",\n",
    "    n_results=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec1c431-95ae-4b62-b5c1-eb76ff6a1f13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
